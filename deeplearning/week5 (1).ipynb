{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f0bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e327de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기 (csv, xlsx)\n",
    "\n",
    "df = pd.read_csv(\"C:/ai/diabetes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db9a1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 데이터에서 독립 변수(Outcome 제외)를 추출\n",
    "X = df.drop('Outcome', axis=1)\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71f002a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a27eb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18836332694351426\n"
     ]
    }
   ],
   "source": [
    "# 축소된 데이터 복원 (원래 차원으로 복원)\n",
    "X_reconstructed = pca.inverse_transform(X_pca)\n",
    "\n",
    "# 원본 데이터와 복원된 데이터 비교 (MSE 계산)\n",
    "mse = mean_squared_error(X_scaled, X_reconstructed)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0561829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기 (csv, xlsx)\n",
    "\n",
    "df = pd.read_csv(\"C:/ai/creditcard.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7197cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "\n",
    "print(df.shape)\n",
    "print(df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d422b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['Time'], axis=1)\n",
    "\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08e2760f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227451, 29)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train = X_train[X_train.Class == 0]\n",
    "X_train = X_train.drop(['Class'], axis=1)\n",
    "\n",
    "y_test = X_test['Class']\n",
    "X_test = X_test.drop(['Class'], axis=1)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7973139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">319</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │           \u001b[38;5;34m319\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,239</span> (4.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,239\u001b[0m (4.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,239</span> (4.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,239\u001b[0m (4.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 오토인코더 모델\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 20  # 인코딩 차원을 설정 (임의로 설정한 값, 조정 가능)\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "encoded = Dense(int(encoding_dim / 2), activation='relu')(encoded)\n",
    "decoded = Dense(int(encoding_dim / 2), activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.002), loss='mse')\n",
    "\n",
    "# 모델 요약 출력\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0de4a9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 390us/step - loss: 0.9042 - val_loss: 0.8186\n",
      "Epoch 2/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - loss: 0.8456 - val_loss: 0.8021\n",
      "Epoch 3/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367us/step - loss: 0.8143 - val_loss: 0.7955\n",
      "Epoch 4/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369us/step - loss: 0.7994 - val_loss: 0.7940\n",
      "Epoch 5/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366us/step - loss: 0.8169 - val_loss: 0.7920\n",
      "Epoch 6/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 359us/step - loss: 0.7947 - val_loss: 0.7855\n",
      "Epoch 7/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377us/step - loss: 0.7940 - val_loss: 0.7842\n",
      "Epoch 8/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 360us/step - loss: 0.8016 - val_loss: 0.7834\n",
      "Epoch 9/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367us/step - loss: 0.8001 - val_loss: 0.7829\n",
      "Epoch 10/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368us/step - loss: 0.7983 - val_loss: 0.7907\n",
      "Epoch 11/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 357us/step - loss: 0.7898 - val_loss: 0.7826\n",
      "Epoch 12/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 359us/step - loss: 0.7883 - val_loss: 0.7822\n",
      "Epoch 13/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355us/step - loss: 0.8014 - val_loss: 0.7822\n",
      "Epoch 14/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375us/step - loss: 0.7931 - val_loss: 0.7835\n",
      "Epoch 15/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369us/step - loss: 0.7992 - val_loss: 0.7832\n",
      "Epoch 16/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - loss: 0.8085 - val_loss: 0.7824\n",
      "Epoch 17/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382us/step - loss: 0.8083 - val_loss: 0.7822\n",
      "Epoch 18/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384us/step - loss: 0.7946 - val_loss: 0.7823\n",
      "Epoch 19/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379us/step - loss: 0.7978 - val_loss: 0.7825\n",
      "Epoch 20/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375us/step - loss: 0.7928 - val_loss: 0.7825\n",
      "Epoch 21/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363us/step - loss: 0.8044 - val_loss: 0.7818\n",
      "Epoch 22/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 354us/step - loss: 0.7900 - val_loss: 0.7820\n",
      "Epoch 23/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363us/step - loss: 0.7921 - val_loss: 0.7823\n",
      "Epoch 24/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 357us/step - loss: 0.7951 - val_loss: 0.7823\n",
      "Epoch 25/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369us/step - loss: 0.8049 - val_loss: 0.7820\n",
      "Epoch 26/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379us/step - loss: 0.8015 - val_loss: 0.7824\n",
      "Epoch 27/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386us/step - loss: 0.7943 - val_loss: 0.7821\n",
      "Epoch 28/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362us/step - loss: 0.8059 - val_loss: 0.7820\n",
      "Epoch 29/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362us/step - loss: 0.7945 - val_loss: 0.7806\n",
      "Epoch 30/30\n",
      "\u001b[1m6398/6398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376us/step - loss: 0.7965 - val_loss: 0.7812\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 학습\n",
    "history = autoencoder.fit(X_train, X_train, \n",
    "                          epochs=30, \n",
    "                          batch_size=32, \n",
    "                          shuffle=True, \n",
    "                          validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fc4eb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46bd07c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기 (csv, xlsx)\n",
    "\n",
    "df = pd.read_csv(\"C:/ai/DSA_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9f1b966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sitting', 'standing', 'lyingBack', 'lyingRigh', 'ascendingStairs',\n",
       "       'decendingStairs', 'standingInElevatorStill', 'movingInElevator',\n",
       "       'walkingLot', 'walkingTreadmillFlat', 'walkingTreadmillIncline',\n",
       "       'runningTreadmill', 'stepper', 'crossTrainer', 'cyclingHorizontal',\n",
       "       'cyclingVertical', 'rowing', 'jumping', 'basketBall'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d25104f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.18320</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.21290</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.21280</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.31700</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.25740</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>9.298029</td>\n",
       "      <td>32.4980</td>\n",
       "      <td>-6.0782</td>\n",
       "      <td>134.634624</td>\n",
       "      <td>11.603216</td>\n",
       "      <td>0.570723</td>\n",
       "      <td>-2.592341</td>\n",
       "      <td>1.73230</td>\n",
       "      <td>-12.91800</td>\n",
       "      <td>9.207424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.334449</td>\n",
       "      <td>0.625187</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.571870</td>\n",
       "      <td>9.188517e-04</td>\n",
       "      <td>0.030313</td>\n",
       "      <td>0.274486</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>8.738784</td>\n",
       "      <td>34.0480</td>\n",
       "      <td>-6.7822</td>\n",
       "      <td>145.225186</td>\n",
       "      <td>12.050941</td>\n",
       "      <td>0.760224</td>\n",
       "      <td>-2.417799</td>\n",
       "      <td>1.19030</td>\n",
       "      <td>-10.90200</td>\n",
       "      <td>9.233904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.396417</td>\n",
       "      <td>0.624749</td>\n",
       "      <td>0.693560</td>\n",
       "      <td>0.570400</td>\n",
       "      <td>9.632708e-04</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.433661</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>9.404261</td>\n",
       "      <td>34.8670</td>\n",
       "      <td>-5.3331</td>\n",
       "      <td>130.142955</td>\n",
       "      <td>11.408022</td>\n",
       "      <td>0.560963</td>\n",
       "      <td>-2.408945</td>\n",
       "      <td>0.81347</td>\n",
       "      <td>-8.21750</td>\n",
       "      <td>6.635468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030322</td>\n",
       "      <td>0.524964</td>\n",
       "      <td>0.631822</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.581970</td>\n",
       "      <td>8.933477e-04</td>\n",
       "      <td>0.029889</td>\n",
       "      <td>0.335023</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>9.139112</td>\n",
       "      <td>32.5060</td>\n",
       "      <td>-6.8835</td>\n",
       "      <td>135.812815</td>\n",
       "      <td>11.653876</td>\n",
       "      <td>0.589304</td>\n",
       "      <td>-2.359531</td>\n",
       "      <td>1.32350</td>\n",
       "      <td>-9.57930</td>\n",
       "      <td>7.510565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024060</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>0.624196</td>\n",
       "      <td>0.688560</td>\n",
       "      <td>0.573620</td>\n",
       "      <td>1.025797e-03</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>0.272121</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>8.868404</td>\n",
       "      <td>30.9070</td>\n",
       "      <td>-6.7151</td>\n",
       "      <td>128.743919</td>\n",
       "      <td>11.346538</td>\n",
       "      <td>0.585457</td>\n",
       "      <td>-2.144665</td>\n",
       "      <td>0.93113</td>\n",
       "      <td>-8.52640</td>\n",
       "      <td>6.022491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.395776</td>\n",
       "      <td>0.633913</td>\n",
       "      <td>0.692860</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>9.165240e-04</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>0.342332</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "8635     9.298029     32.4980     -6.0782  134.634624   11.603216   \n",
       "8636     8.738784     34.0480     -6.7822  145.225186   12.050941   \n",
       "8637     9.404261     34.8670     -5.3331  130.142955   11.408022   \n",
       "8638     9.139112     32.5060     -6.8835  135.812815   11.653876   \n",
       "8639     8.868404     30.9070     -6.7151  128.743919   11.346538   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150     1.18320     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865     1.21290     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962     1.21280     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260     1.31700     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504     1.25740     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "8635     0.570723    -2.592341     1.73230   -12.91800    9.207424  ...   \n",
       "8636     0.760224    -2.417799     1.19030   -10.90200    9.233904  ...   \n",
       "8637     0.560963    -2.408945     0.81347    -8.21750    6.635468  ...   \n",
       "8638     0.589304    -2.359531     1.32350    -9.57930    7.510565  ...   \n",
       "8639     0.585457    -2.144665     0.93113    -8.52640    6.022491  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "8635     0.030501      0.334449      0.625187     0.691300     0.571870   \n",
       "8636     0.031573      0.396417      0.624749     0.693560     0.570400   \n",
       "8637     0.030322      0.524964      0.631822     0.690120     0.581970   \n",
       "8638     0.024060      0.301200      0.624196     0.688560     0.573620   \n",
       "8639     0.023166      0.395776      0.633913     0.692860     0.586420   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew  activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729   sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471   sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579   sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690   sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429   sitting      p1  \n",
       "...            ...          ...           ...       ...     ...  \n",
       "8635  9.188517e-04     0.030313      0.274486   jumping      p8  \n",
       "8636  9.632708e-04     0.031037      0.433661   jumping      p8  \n",
       "8637  8.933477e-04     0.029889      0.335023   jumping      p8  \n",
       "8638  1.025797e-03     0.032028      0.272121   jumping      p8  \n",
       "8639  9.165240e-04     0.030274      0.342332   jumping      p8  \n",
       "\n",
       "[960 rows x 272 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['activity'].isin(['sitting', 'jumping'])]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d188ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1563a\\AppData\\Local\\Temp\\ipykernel_41604\\632236701.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[i] = LabelEncoder().fit_transform(df_filtered[i])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222</td>\n",
       "      <td>165</td>\n",
       "      <td>539</td>\n",
       "      <td>465</td>\n",
       "      <td>465</td>\n",
       "      <td>219</td>\n",
       "      <td>900</td>\n",
       "      <td>483</td>\n",
       "      <td>825</td>\n",
       "      <td>360</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>554</td>\n",
       "      <td>228</td>\n",
       "      <td>192</td>\n",
       "      <td>220</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227</td>\n",
       "      <td>170</td>\n",
       "      <td>581</td>\n",
       "      <td>444</td>\n",
       "      <td>444</td>\n",
       "      <td>517</td>\n",
       "      <td>901</td>\n",
       "      <td>490</td>\n",
       "      <td>827</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>96</td>\n",
       "      <td>224</td>\n",
       "      <td>193</td>\n",
       "      <td>211</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>145</td>\n",
       "      <td>580</td>\n",
       "      <td>359</td>\n",
       "      <td>359</td>\n",
       "      <td>268</td>\n",
       "      <td>902</td>\n",
       "      <td>489</td>\n",
       "      <td>830</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>170</td>\n",
       "      <td>177</td>\n",
       "      <td>231</td>\n",
       "      <td>200</td>\n",
       "      <td>228</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>544</td>\n",
       "      <td>387</td>\n",
       "      <td>387</td>\n",
       "      <td>138</td>\n",
       "      <td>905</td>\n",
       "      <td>514</td>\n",
       "      <td>828</td>\n",
       "      <td>358</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>369</td>\n",
       "      <td>259</td>\n",
       "      <td>228</td>\n",
       "      <td>253</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207</td>\n",
       "      <td>158</td>\n",
       "      <td>578</td>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>955</td>\n",
       "      <td>908</td>\n",
       "      <td>502</td>\n",
       "      <td>835</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>167</td>\n",
       "      <td>268</td>\n",
       "      <td>231</td>\n",
       "      <td>260</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>659</td>\n",
       "      <td>554</td>\n",
       "      <td>258</td>\n",
       "      <td>771</td>\n",
       "      <td>771</td>\n",
       "      <td>531</td>\n",
       "      <td>23</td>\n",
       "      <td>582</td>\n",
       "      <td>61</td>\n",
       "      <td>874</td>\n",
       "      <td>...</td>\n",
       "      <td>622</td>\n",
       "      <td>690</td>\n",
       "      <td>798</td>\n",
       "      <td>776</td>\n",
       "      <td>727</td>\n",
       "      <td>681</td>\n",
       "      <td>681</td>\n",
       "      <td>638</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>305</td>\n",
       "      <td>587</td>\n",
       "      <td>218</td>\n",
       "      <td>783</td>\n",
       "      <td>783</td>\n",
       "      <td>657</td>\n",
       "      <td>91</td>\n",
       "      <td>486</td>\n",
       "      <td>95</td>\n",
       "      <td>875</td>\n",
       "      <td>...</td>\n",
       "      <td>635</td>\n",
       "      <td>736</td>\n",
       "      <td>791</td>\n",
       "      <td>786</td>\n",
       "      <td>723</td>\n",
       "      <td>706</td>\n",
       "      <td>706</td>\n",
       "      <td>761</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>714</td>\n",
       "      <td>598</td>\n",
       "      <td>309</td>\n",
       "      <td>757</td>\n",
       "      <td>757</td>\n",
       "      <td>524</td>\n",
       "      <td>95</td>\n",
       "      <td>419</td>\n",
       "      <td>189</td>\n",
       "      <td>754</td>\n",
       "      <td>...</td>\n",
       "      <td>617</td>\n",
       "      <td>810</td>\n",
       "      <td>831</td>\n",
       "      <td>772</td>\n",
       "      <td>758</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>530</td>\n",
       "      <td>555</td>\n",
       "      <td>213</td>\n",
       "      <td>775</td>\n",
       "      <td>775</td>\n",
       "      <td>554</td>\n",
       "      <td>101</td>\n",
       "      <td>516</td>\n",
       "      <td>127</td>\n",
       "      <td>812</td>\n",
       "      <td>...</td>\n",
       "      <td>525</td>\n",
       "      <td>668</td>\n",
       "      <td>784</td>\n",
       "      <td>769</td>\n",
       "      <td>738</td>\n",
       "      <td>749</td>\n",
       "      <td>749</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8639</th>\n",
       "      <td>341</td>\n",
       "      <td>521</td>\n",
       "      <td>222</td>\n",
       "      <td>751</td>\n",
       "      <td>751</td>\n",
       "      <td>548</td>\n",
       "      <td>119</td>\n",
       "      <td>438</td>\n",
       "      <td>174</td>\n",
       "      <td>734</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>734</td>\n",
       "      <td>846</td>\n",
       "      <td>782</td>\n",
       "      <td>762</td>\n",
       "      <td>678</td>\n",
       "      <td>678</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0             222         165         539         465         465   \n",
       "1             227         170         581         444         444   \n",
       "2             218         145         580         359         359   \n",
       "3             211         148         544         387         387   \n",
       "4             207         158         578         271         271   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "8635          659         554         258         771         771   \n",
       "8636          305         587         218         783         783   \n",
       "8637          714         598         309         757         757   \n",
       "8638          530         555         213         775         775   \n",
       "8639          341         521         222         751         751   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0             219          900         483         825         360  ...   \n",
       "1             517          901         490         827         138  ...   \n",
       "2             268          902         489         830          63  ...   \n",
       "3             138          905         514         828         358  ...   \n",
       "4             955          908         502         835         109  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "8635          531           23         582          61         874  ...   \n",
       "8636          657           91         486          95         875  ...   \n",
       "8637          524           95         419         189         754  ...   \n",
       "8638          554          101         516         127         812  ...   \n",
       "8639          548          119         438         174         734  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0             199           554           228          192          220   \n",
       "1             256            96           224          193          211   \n",
       "2             170           177           231          200          228   \n",
       "3             135           369           259          228          253   \n",
       "4             226           167           268          231          260   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "8635          622           690           798          776          727   \n",
       "8636          635           736           791          786          723   \n",
       "8637          617           810           831          772          758   \n",
       "8638          525           668           784          769          738   \n",
       "8639          512           734           846          782          762   \n",
       "\n",
       "      LL_zmag_var  LL_zmag_std  LL_zmag_skew  activity  people  \n",
       "0             248          248           428         1       0  \n",
       "1             266          266           706         1       0  \n",
       "2             217          217           439         1       0  \n",
       "3             309          309           600         1       0  \n",
       "4             250          250           619         1       0  \n",
       "...           ...          ...           ...       ...     ...  \n",
       "8635          681          681           638         0       7  \n",
       "8636          706          706           761         0       7  \n",
       "8637          663          663           693         0       7  \n",
       "8638          749          749           634         0       7  \n",
       "8639          678          678           702         0       7  \n",
       "\n",
       "[960 rows x 272 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in df_filtered.columns:\n",
    "    # LabelEncoder 객체 생성\n",
    "    label_encoder = LabelEncoder()\n",
    "    # 'label' 컬럼을 숫자로 변환\n",
    "    df_filtered[i] = LabelEncoder().fit_transform(df_filtered[i])\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c5c0a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 271)\n",
      "(960,)\n"
     ]
    }
   ],
   "source": [
    "X=df_filtered.drop('activity',axis=1)\n",
    "y=df_filtered['activity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=0)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7e9361b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">271</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">465</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m271\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m8,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m465\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,881</span> (34.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,881\u001b[0m (34.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,881</span> (34.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,881\u001b[0m (34.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 오토인코더 모델\n",
    "\n",
    "encoding_dim = 30  # 인코딩 차원을 설정 (임의로 설정한 값, 조정 가능)\n",
    "\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "encoded = Dense(int(encoding_dim / 2), activation='relu')(encoded)\n",
    "decoded = Dense(int(encoding_dim / 2), activation='relu')(encoded)\n",
    "decoded = Dense(1)(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# 모델 요약 출력\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ee6205e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 8778.2402 - val_loss: 126.0447\n",
      "Epoch 2/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 118.9022 - val_loss: 43.0248\n",
      "Epoch 3/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 41.7912 - val_loss: 21.5209\n",
      "Epoch 4/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 19.4410 - val_loss: 11.5710\n",
      "Epoch 5/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 10.0302 - val_loss: 7.2222\n",
      "Epoch 6/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 6.9444 - val_loss: 6.4146\n",
      "Epoch 7/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 5.1011 - val_loss: 4.0353\n",
      "Epoch 8/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 3.3479 - val_loss: 3.2113\n",
      "Epoch 9/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 2.7534 - val_loss: 1.9966\n",
      "Epoch 10/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 2.1612 - val_loss: 1.5805\n",
      "Epoch 11/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 1.6763 - val_loss: 1.2705\n",
      "Epoch 12/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 1.3996 - val_loss: 1.3523\n",
      "Epoch 13/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 1.1672 - val_loss: 1.0161\n",
      "Epoch 14/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.7808 - val_loss: 0.8233\n",
      "Epoch 15/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 0.7085 - val_loss: 0.5435\n",
      "Epoch 16/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 0.6143 - val_loss: 0.3866\n",
      "Epoch 17/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 0.4594 - val_loss: 0.4957\n",
      "Epoch 18/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 0.3542 - val_loss: 0.2870\n",
      "Epoch 19/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 0.3084 - val_loss: 0.1999\n",
      "Epoch 20/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 0.2135 - val_loss: 0.3322\n",
      "Epoch 21/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 0.2072 - val_loss: 0.1640\n",
      "Epoch 22/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 0.1700 - val_loss: 0.1380\n",
      "Epoch 23/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 0.1286 - val_loss: 0.1336\n",
      "Epoch 24/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 0.1206 - val_loss: 0.3780\n",
      "Epoch 25/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 0.1790 - val_loss: 0.1562\n",
      "Epoch 26/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 0.1236 - val_loss: 0.0953\n",
      "Epoch 27/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 0.1075 - val_loss: 0.1096\n",
      "Epoch 28/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 0.1063 - val_loss: 0.0837\n",
      "Epoch 29/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.1185 - val_loss: 0.0887\n",
      "Epoch 30/30\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 0.1611 - val_loss: 0.1418\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 학습\n",
    "history2 = autoencoder.fit(X_train, y_train, \n",
    "                          epochs=30, \n",
    "                          batch_size=4, \n",
    "                          shuffle=True, \n",
    "                          validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "727cca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>true_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287489.689806</td>\n",
       "      <td>0.508333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89766.723042</td>\n",
       "      <td>0.500975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>166874.373608</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>204333.004095</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>262899.057600</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363690.970672</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>485954.107421</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstruction_error  true_class\n",
       "count            240.000000  240.000000\n",
       "mean          287489.689806    0.508333\n",
       "std            89766.723042    0.500975\n",
       "min           166874.373608    0.000000\n",
       "25%           204333.004095    0.000000\n",
       "50%           262899.057600    1.000000\n",
       "75%           363690.970672    1.000000\n",
       "max           485954.107421    1.000000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_test})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1126dd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222</td>\n",
       "      <td>165</td>\n",
       "      <td>539</td>\n",
       "      <td>465</td>\n",
       "      <td>465</td>\n",
       "      <td>219</td>\n",
       "      <td>900</td>\n",
       "      <td>483</td>\n",
       "      <td>825</td>\n",
       "      <td>360</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>554</td>\n",
       "      <td>228</td>\n",
       "      <td>192</td>\n",
       "      <td>220</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227</td>\n",
       "      <td>170</td>\n",
       "      <td>581</td>\n",
       "      <td>444</td>\n",
       "      <td>444</td>\n",
       "      <td>517</td>\n",
       "      <td>901</td>\n",
       "      <td>490</td>\n",
       "      <td>827</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>96</td>\n",
       "      <td>224</td>\n",
       "      <td>193</td>\n",
       "      <td>211</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>145</td>\n",
       "      <td>580</td>\n",
       "      <td>359</td>\n",
       "      <td>359</td>\n",
       "      <td>268</td>\n",
       "      <td>902</td>\n",
       "      <td>489</td>\n",
       "      <td>830</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>170</td>\n",
       "      <td>177</td>\n",
       "      <td>231</td>\n",
       "      <td>200</td>\n",
       "      <td>228</td>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>544</td>\n",
       "      <td>387</td>\n",
       "      <td>387</td>\n",
       "      <td>138</td>\n",
       "      <td>905</td>\n",
       "      <td>514</td>\n",
       "      <td>828</td>\n",
       "      <td>358</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>369</td>\n",
       "      <td>259</td>\n",
       "      <td>228</td>\n",
       "      <td>253</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207</td>\n",
       "      <td>158</td>\n",
       "      <td>578</td>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>955</td>\n",
       "      <td>908</td>\n",
       "      <td>502</td>\n",
       "      <td>835</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>167</td>\n",
       "      <td>268</td>\n",
       "      <td>231</td>\n",
       "      <td>260</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>145</td>\n",
       "      <td>86</td>\n",
       "      <td>531</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>220</td>\n",
       "      <td>641</td>\n",
       "      <td>289</td>\n",
       "      <td>719</td>\n",
       "      <td>260</td>\n",
       "      <td>...</td>\n",
       "      <td>472</td>\n",
       "      <td>663</td>\n",
       "      <td>481</td>\n",
       "      <td>431</td>\n",
       "      <td>473</td>\n",
       "      <td>479</td>\n",
       "      <td>479</td>\n",
       "      <td>742</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>147</td>\n",
       "      <td>81</td>\n",
       "      <td>541</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>225</td>\n",
       "      <td>625</td>\n",
       "      <td>294</td>\n",
       "      <td>731</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>437</td>\n",
       "      <td>104</td>\n",
       "      <td>478</td>\n",
       "      <td>413</td>\n",
       "      <td>416</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>140</td>\n",
       "      <td>87</td>\n",
       "      <td>527</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>227</td>\n",
       "      <td>593</td>\n",
       "      <td>242</td>\n",
       "      <td>704</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>429</td>\n",
       "      <td>793</td>\n",
       "      <td>476</td>\n",
       "      <td>420</td>\n",
       "      <td>445</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>138</td>\n",
       "      <td>77</td>\n",
       "      <td>537</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>447</td>\n",
       "      <td>614</td>\n",
       "      <td>274</td>\n",
       "      <td>720</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>418</td>\n",
       "      <td>11</td>\n",
       "      <td>475</td>\n",
       "      <td>425</td>\n",
       "      <td>443</td>\n",
       "      <td>436</td>\n",
       "      <td>436</td>\n",
       "      <td>746</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>142</td>\n",
       "      <td>72</td>\n",
       "      <td>542</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>256</td>\n",
       "      <td>638</td>\n",
       "      <td>303</td>\n",
       "      <td>753</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>461</td>\n",
       "      <td>347</td>\n",
       "      <td>474</td>\n",
       "      <td>415</td>\n",
       "      <td>442</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>661</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
       "0            222         165         539         465         465          219   \n",
       "1            227         170         581         444         444          517   \n",
       "2            218         145         580         359         359          268   \n",
       "3            211         148         544         387         387          138   \n",
       "4            207         158         578         271         271          955   \n",
       "..           ...         ...         ...         ...         ...          ...   \n",
       "475          145          86         531          77          77          220   \n",
       "476          147          81         541          78          78          225   \n",
       "477          140          87         527          33          33          227   \n",
       "478          138          77         537          46          46          447   \n",
       "479          142          72         542          28          28          256   \n",
       "\n",
       "     T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  LL_ymag_std  \\\n",
       "0            900         483         825         360  ...          199   \n",
       "1            901         490         827         138  ...          256   \n",
       "2            902         489         830          63  ...          170   \n",
       "3            905         514         828         358  ...          135   \n",
       "4            908         502         835         109  ...          226   \n",
       "..           ...         ...         ...         ...  ...          ...   \n",
       "475          641         289         719         260  ...          472   \n",
       "476          625         294         731         227  ...          437   \n",
       "477          593         242         704          83  ...          429   \n",
       "478          614         274         720         175  ...          418   \n",
       "479          638         303         753         235  ...          461   \n",
       "\n",
       "     LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  LL_zmag_var  \\\n",
       "0             554           228          192          220          248   \n",
       "1              96           224          193          211          266   \n",
       "2             177           231          200          228          217   \n",
       "3             369           259          228          253          309   \n",
       "4             167           268          231          260          250   \n",
       "..            ...           ...          ...          ...          ...   \n",
       "475           663           481          431          473          479   \n",
       "476           104           478          413          416          432   \n",
       "477           793           476          420          445          442   \n",
       "478            11           475          425          443          436   \n",
       "479           347           474          415          442          429   \n",
       "\n",
       "     LL_zmag_std  LL_zmag_skew  activity  people  \n",
       "0            248           428         1       0  \n",
       "1            266           706         1       0  \n",
       "2            217           439         1       0  \n",
       "3            309           600         1       0  \n",
       "4            250           619         1       0  \n",
       "..           ...           ...       ...     ...  \n",
       "475          479           742         1       7  \n",
       "476          432            49         1       7  \n",
       "477          442           365         1       7  \n",
       "478          436           746         1       7  \n",
       "479          429           661         1       7  \n",
       "\n",
       "[480 rows x 272 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid=df_filtered[df_filtered['activity'].isin([1])]\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c1bb7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=valid.drop('activity',axis=1)\n",
    "y=valid['activity']\n",
    "t_train, v_train, t_test, v_test = train_test_split(X, y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a676b342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1045 - val_loss: 0.0808\n",
      "Epoch 2/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0708 - val_loss: 0.0729\n",
      "Epoch 3/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0730 - val_loss: 0.0462\n",
      "Epoch 4/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0450 - val_loss: 0.0452\n",
      "Epoch 5/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0669 - val_loss: 0.0507\n",
      "Epoch 6/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0300 - val_loss: 0.0502\n",
      "Epoch 7/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.0355 - val_loss: 0.0281\n",
      "Epoch 8/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.0286 - val_loss: 0.0156\n",
      "Epoch 9/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 0.0219 - val_loss: 0.0144\n",
      "Epoch 10/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0174 - val_loss: 0.0181\n",
      "Epoch 11/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.0177 - val_loss: 0.0190\n",
      "Epoch 12/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 0.0148 - val_loss: 0.0182\n",
      "Epoch 13/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0195 - val_loss: 0.0121\n",
      "Epoch 14/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0104 - val_loss: 0.0324\n",
      "Epoch 15/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0182 - val_loss: 0.0104\n",
      "Epoch 16/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0083 - val_loss: 0.0158\n",
      "Epoch 17/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0171 - val_loss: 0.0373\n",
      "Epoch 18/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.0151 - val_loss: 0.0096\n",
      "Epoch 19/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 20/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - val_loss: 0.0283\n",
      "Epoch 21/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.0136 - val_loss: 0.0087\n",
      "Epoch 22/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.0140 - val_loss: 0.0114\n",
      "Epoch 23/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.0120 - val_loss: 0.0123\n",
      "Epoch 24/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 25/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.0094 - val_loss: 0.0178\n",
      "Epoch 26/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 27/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 28/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 29/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0077 - val_loss: 0.0234\n",
      "Epoch 30/30\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.0131 - val_loss: 0.0114\n"
     ]
    }
   ],
   "source": [
    "history2 = autoencoder.fit(v_train, v_test, \n",
    "                          epochs=30, \n",
    "                          batch_size=4, \n",
    "                          shuffle=True, \n",
    "                          validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "80c0f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       120\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "predictions = autoencoder.predict(v_train)\n",
    "mse = np.mean(np.power(v_train - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': v_test})\n",
    "\n",
    "threshold = 15\n",
    "y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "print(classification_report(error_df.true_class, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4292425f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
